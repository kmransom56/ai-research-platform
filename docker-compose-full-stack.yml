version: '3.8'

# AI Research Platform - Complete Containerized Stack
# This replaces all host-based services with containerized equivalents

networks:
  ai-platform:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  caddy_data:
  caddy_config:
  qdrant_data:
  rabbitmq_data:
  postgres_data:
  portscanner_data:
  webhook_logs:
  platform_logs:

services:
  # ===========================================
  # REVERSE PROXY & SSL TERMINATION
  # ===========================================
  caddy:
    image: caddy:2
    container_name: ai-platform-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "8443:8443"
      - "2019:2019"
    volumes:
      - ./docker-configs/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - ./webapp/public:/srv:ro
      - /etc/ssl/certs/ubuntuaicodeserver.tail5137b4.ts.net.crt:/etc/ssl/certs/server.crt:ro
      - /etc/ssl/private/ubuntuaicodeserver.tail5137b4.ts.net.key:/etc/ssl/private/server.key:ro
    networks:
      ai-platform:
        ipv4_address: 172.20.0.10
    depends_on:
      - chat-copilot-backend
      - chat-copilot-frontend
      - autogen-studio
      - webhook-server
      - port-scanner

  # ===========================================
  # CORE AI RESEARCH PLATFORM SERVICES
  # ===========================================
  
  # Chat Copilot Backend (.NET WebAPI)
  chat-copilot-backend:
    build:
      context: .
      dockerfile: docker/webapi/Dockerfile
    container_name: ai-platform-chat-backend
    restart: unless-stopped
    environment:
      - ASPNETCORE_ENVIRONMENT=Production
      - ASPNETCORE_URLS=http://+:80
      - KernelMemory__Services__OpenAI__APIKey=${AZURE_OPENAI_KEY}
      - KernelMemory__Services__OpenAI__Endpoint=${AZURE_OPENAI_ENDPOINT}
      - SemanticKernel__Services__AzureOpenAI__ApiKey=${AZURE_OPENAI_KEY}
      - SemanticKernel__Services__AzureOpenAI__Endpoint=${AZURE_OPENAI_ENDPOINT}
      - Qdrant__Host=qdrant
      - Qdrant__Port=6333
      - RabbitMQ__Host=rabbitmq
      - PostgreSQL__Host=postgres
    ports:
      - "11000:80"
    volumes:
      - platform_logs:/app/logs
      - ./appsettings.json:/app/appsettings.json:ro
    networks:
      ai-platform:
        ipv4_address: 172.20.0.20
    depends_on:
      - qdrant
      - rabbitmq
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Chat Copilot Frontend (React)
  chat-copilot-frontend:
    build:
      context: ./webapp
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
    container_name: ai-platform-chat-frontend
    restart: unless-stopped
    environment:
      - REACT_APP_BACKEND_URI=http://172.20.0.20:80
      - NODE_ENV=production
    ports:
      - "3000:3000"
    volumes:
      - platform_logs:/app/logs
    networks:
      ai-platform:
        ipv4_address: 172.20.0.21
    depends_on:
      - chat-copilot-backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

  # AutoGen Studio (Python Multi-Agent System)
  autogen-studio:
    build:
      context: ./python/autogen-studio
      dockerfile: Dockerfile
    container_name: ai-platform-autogen
    restart: unless-stopped
    environment:
      - PYTHONPATH=/app
      - AUTOGEN_CONFIG_LIST=/app/config/OAI_CONFIG_LIST.json
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
    ports:
      - "11001:8081"
    volumes:
      - ./python/autogen-studio/config:/app/config:ro
      - platform_logs:/app/logs
    networks:
      ai-platform:
        ipv4_address: 172.20.0.22
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Webhook Server (Node.js GitHub Integration)
  webhook-server:
    build:
      context: ./runtime-data
      dockerfile: Dockerfile.webhook
    container_name: ai-platform-webhook
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - WEBHOOK_SECRET=${GITHUB_WEBHOOK_SECRET}
      - WEBHOOK_PORT=11002
      - REPOSITORY_PATH=/app/repo
    ports:
      - "11002:11002"
    volumes:
      - webhook_logs:/app/logs
      - .:/app/repo:rw  # Mount repo for git operations
      - /var/run/docker.sock:/var/run/docker.sock  # Docker access for deployments
    networks:
      ai-platform:
        ipv4_address: 172.20.0.23
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Magentic-One (Microsoft Multi-Agent)
  magentic-one:
    build:
      context: ./python/services
      dockerfile: Dockerfile
    container_name: ai-platform-magentic
    restart: unless-stopped
    environment:
      - PYTHONPATH=/app
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
    ports:
      - "11003:11003"
    volumes:
      - platform_logs:/app/logs
    networks:
      ai-platform:
        ipv4_address: 172.20.0.24
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11003/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Port Scanner (Network Discovery Tool)
  port-scanner:
    build:
      context: /home/keith/port-scanner-material-ui
      dockerfile: Dockerfile
    container_name: ai-platform-portscanner
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=11010
    ports:
      - "11010:11010"
    volumes:
      - portscanner_data:/app/data
      - platform_logs:/app/logs
    networks:
      ai-platform:
        ipv4_address: 172.20.0.25
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11010"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================
  # EXTERNAL AI SERVICES (Already Containerized)
  # ===========================================
  
  # OpenWebUI (Primary LLM Interface)
  openwebui:
    image: ghcr.io/open-webui/open-webui:cuda
    container_name: ai-platform-openwebui
    restart: unless-stopped
    environment:
      - WEBUI_SECRET_KEY=${OPENWEBUI_SECRET_KEY}
      - OPENAI_API_BASE_URL=${AZURE_OPENAI_ENDPOINT}
      - OPENAI_API_KEY=${AZURE_OPENAI_KEY}
    ports:
      - "11880:8080"
    volumes:
      - openwebui_data:/app/backend/data
    networks:
      ai-platform:
        ipv4_address: 172.20.0.30
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Perplexica (AI Search with Internet Access)
  perplexica:
    image: itzcrazykns1337/perplexcia:main
    container_name: ai-platform-perplexica
    restart: unless-stopped
    environment:
      - SEARXNG_API_URL=http://searxng:8080
      - OPENAI_API_KEY=${AZURE_OPENAI_KEY}
      - OPENAI_API_BASE_URL=${AZURE_OPENAI_ENDPOINT}
    ports:
      - "11020:3000"
    networks:
      ai-platform:
        ipv4_address: 172.20.0.31
    depends_on:
      - searxng
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

  # SearXNG (Privacy-Focused Search Engine)
  searxng:
    image: searxng/searxng:latest
    container_name: ai-platform-searxng
    restart: unless-stopped
    environment:
      - BASE_URL=https://ubuntuaicodeserver-1.tail5137b4.ts.net:8443/searxng/
      - INSTANCE_NAME=AI Research Platform Search
    ports:
      - "11021:8080"
    volumes:
      - ./configs/searxng:/etc/searxng:ro
    networks:
      ai-platform:
        ipv4_address: 172.20.0.32
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3

  # VS Code Server (Web-based IDE)
  vscode-server:
    image: codercom/code-server:latest
    container_name: ai-platform-vscode
    restart: unless-stopped
    environment:
      - PASSWORD=${VSCODE_PASSWORD}
      - SUDO_PASSWORD=${VSCODE_PASSWORD}
    ports:
      - "57081:8080"
    volumes:
      - .:/home/coder/workspace
      - vscode_config:/home/coder/.config
    networks:
      ai-platform:
        ipv4_address: 172.20.0.33
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================
  # DATABASE & INFRASTRUCTURE SERVICES
  # ===========================================
  
  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: ai-platform-qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      ai-platform:
        ipv4_address: 172.20.0.40
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # RabbitMQ Message Queue
  rabbitmq:
    image: rabbitmq:3-management
    container_name: ai-platform-rabbitmq
    restart: unless-stopped
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      ai-platform:
        ipv4_address: 172.20.0.41
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL Database
  postgres:
    image: postgres:15
    container_name: ai-platform-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init:/docker-entrypoint-initdb.d:ro
    networks:
      ai-platform:
        ipv4_address: 172.20.0.42
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================
  # MONITORING & MANAGEMENT
  # ===========================================
  
  # Health Monitor Service
  health-monitor:
    build:
      context: ./scripts/platform-management
      dockerfile: Dockerfile.monitoring
    container_name: ai-platform-monitor
    restart: unless-stopped
    environment:
      - CHECK_INTERVAL=300
      - FAILURE_THRESHOLD=3
      - LOG_RETENTION_DAYS=7
    volumes:
      - platform_logs:/app/logs
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker access for monitoring
    networks:
      ai-platform:
        ipv4_address: 172.20.0.50
    depends_on:
      - chat-copilot-backend
      - autogen-studio
      - webhook-server
      - magentic-one

# Additional volume definitions for external services
volumes:
  openwebui_data:
  vscode_config: