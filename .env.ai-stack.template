# Advanced AI Stack Environment Configuration Template
# Copy this to .env.ai-stack and configure for your environment

# AI Stack Gateway Settings
AI_STACK_GATEWAY_HOST=0.0.0.0
AI_STACK_GATEWAY_PORT=9000
AI_STACK_GATEWAY_WORKERS=4
AI_STACK_GATEWAY_TIMEOUT=60

# Backend Service URLs
AI_STACK_REASONING_URL=http://localhost:8000  # vLLM DeepSeek R1
AI_STACK_GENERAL_URL=http://localhost:8001    # vLLM Mistral Small
AI_STACK_CODING_URL=http://localhost:8002     # vLLM DeepSeek Coder
AI_STACK_CREATIVE_URL=http://localhost:5001   # KoboldCpp
AI_STACK_ADVANCED_URL=http://localhost:5000   # Oobabooga API

# Service Health Check Settings
AI_STACK_HEALTH_CHECK_INTERVAL=30
AI_STACK_HEALTH_CHECK_TIMEOUT=10
AI_STACK_HEALTH_CHECK_RETRIES=3

# Logging Configuration
AI_STACK_LOG_LEVEL=INFO
AI_STACK_LOG_DIR=./logs
AI_STACK_ACCESS_LOG=true
AI_STACK_ERROR_LOG=true

# GPU Monitoring (optional)
AI_STACK_GPU_MONITORING=true
NVIDIA_ML_AVAILABLE=true

# Docker Configuration (for containerized deployment)
AI_STACK_NETWORK_NAME=chatcopilot_ai-platform
AI_STACK_VOLUMES_PREFIX=ai-stack

# Model Configuration
VLLM_CACHE_DIR=/tmp/vllm-cache
OOBABOOGA_MODELS_DIR=/tmp/oobabooga-models
KOBOLDCPP_MODELS_DIR=/tmp/koboldcpp-models

# Performance Settings
AI_STACK_MAX_CONCURRENT_REQUESTS=10
AI_STACK_REQUEST_TIMEOUT=120
AI_STACK_MAX_TOKENS_DEFAULT=512
AI_STACK_TEMPERATURE_DEFAULT=0.7

# Security Settings (for production)
AI_STACK_API_KEY=
AI_STACK_CORS_ORIGINS=http://localhost:3000,http://localhost:11000
AI_STACK_RATE_LIMIT=100  # requests per minute per IP

# Monitoring and Metrics
AI_STACK_PROMETHEUS_ENABLED=true
AI_STACK_PROMETHEUS_PORT=8091
AI_STACK_METRICS_PATH=/metrics

# Development Settings
AI_STACK_DEBUG=false
AI_STACK_RELOAD_ON_CHANGE=false