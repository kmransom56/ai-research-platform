# HA Secondary Node Configuration  
# Target System: 72GB VRAM (3x Tesla K80s) - High Capacity Node
NODE_ID=secondary
NODE_ROLE=secondary
HARDWARE_PROFILE=72GB_VRAM_Tesla_K80_System
VRAM_TOTAL=72GB
GPU_COUNT=3
GPU_TYPE=Tesla_K80

# HA Cluster Configuration
CLUSTER_VIP=10.0.1.100
PRIMARY_NODE_IP=10.0.1.10
SECONDARY_NODE_IP=10.0.1.11
HA_PEER_IP=${PRIMARY_NODE_IP}

# Tesla K80 Optimized Service Configuration
REASONING_MODEL=deepseek-r1-distill-llama-70b
GENERAL_MODEL=mistral-7b-instruct  
CODING_MODEL=deepseek-coder-33b
CREATIVE_MODEL=llama2-70b-chat
GPU_MEMORY_UTILIZATION=0.8
MAX_MODEL_LEN=4096
CONCURRENT_MODELS=4

# Tesla K80 Specific Settings
TESLA_MEMORY_PER_GPU=24GB
TESLA_COMPUTE_CAPABILITY=3.7
CUDA_VERSION_REQUIRED=11.8
TENSOR_PARALLEL_SIZE=2

# HA Specific Settings
HA_ENABLED=true
FAILOVER_TIMEOUT=45
HEALTH_CHECK_INTERVAL=15
BACKUP_SYNC_INTERVAL=180

# Load Balancer Configuration (Secondary as high-capacity node)
LB_STRATEGY=capacity_based
LB_WEIGHTS_PRIMARY=0.3
LB_WEIGHTS_SECONDARY=0.7

# Service Priorities for Secondary Node (High Capacity)
PRIORITY_REASONING=critical
PRIORITY_GENERAL=high
PRIORITY_CODING=high
PRIORITY_CREATIVE=high
PRIORITY_MULTIMODAL=medium

# Tesla K80 Performance Optimizations
TESLA_BOOST_CLOCKS=true
TESLA_POWER_LIMIT=300W
TESLA_PERSISTENCE_MODE=true
CUDA_CACHE_DISABLE=0